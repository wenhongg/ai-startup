# Improvement Proposal

## Title: Enhance Founder AI Proposal Generation

## Description:

This pull request enhances the Founder AI's ability to generate more structured and actionable improvement proposals. This is achieved by modifying the prompt used by the Founder AI and implementing a parsing and validation mechanism for the output.
Changes to be made:
1.  **Modify `src/prompts/founder.txt`:** The existing prompt is basic. It will be updated to explicitly request structured output, guiding the Founder AI in a multi-step reasoning process. The new prompt will instruct the AI to:
*   Identify the specific area for improvement (e.g., "improve logging").
*   Explain *why* this area is important, detailing the benefit or impact (e.g., "Improved logging will aid in debugging and monitoring system behavior, leading to faster resolution of issues and increased system stability").
*   Explain *how* the change can be achieved, providing suggested changes (e.g., "Implement structured logging with timestamps, severity levels, and context information. Use a logging library like the Python `logging` module and configure it to write logs to both the console and a file").
*   Assess *potential risks* associated with the improvement (e.g., "Incorrect logging configuration could lead to excessive log file sizes or sensitive information exposure").
*   Estimate the *level of effort* (e.g., "Effort level: Medium - requires changes to multiple files and careful configuration").
2.  **Implement Structured Output Parsing:** A method for parsing the structured output from the AI will be implemented, converting the response into a Python dictionary and validating the result. This will involve:
*   Defining a `Proposal` class (or using a `TypedDict`) in a new file `src/models/proposal.py` to contain the parsed data, including fields for `area_for_improvement`, `rationale`, `suggested_changes`, `risks`, and `effort_level`.
*   Implementing a parsing function that extracts these fields from the LLM's response using regular expressions or other suitable techniques to handle potential formatting variations in the LLM output.
*   Implementing validation to ensure the parsed output conforms to the expected structure and data types, using Pydantic or similar validation library to raise clear exceptions if the parsing fails or the output format is invalid.
3.  **Add Context to the Code Reader:** Modify the `CodeReader` to pass information about the type of file as part of the `code_summary`, so the `FounderAI` can better understand how to improve this code. This is a minimal change, likely involving the addition of a file type parameter to the `summarize` function.
4.  **Update FounderAI to use proposal parsing and validation:** Modify the `FounderAI` class to use the parsing function, validate the generated output, and handle potential parsing failures.
Why these changes are beneficial:
*   **Improved Proposal Quality:** The structured prompt will guide the Founder AI to generate more comprehensive and actionable improvement proposals, leading to more effective code changes. The inclusion of rationale, suggested changes, risks, and effort level provides the developer with essential context and allows for better prioritization.
*   **Enhanced Actionability:** The structured output makes it easier for the Developer AI and human reviewers to understand, evaluate, and implement the proposed changes.
*   **Increased Reliability:** Output validation will ensure the integrity of the proposal data and prevent errors caused by unexpected output formats from the LLM.
*   **Better Prioritization:** The effort level estimates will allow for better prioritization of improvement efforts.
Potential impacts:
*   **LLM Output Variability:** The LLM might not always generate output in the expected structured format. The prompt might require refinement, and the parsing logic must be robust enough to handle variations.
*   **Parsing Complexity:** The parsing logic could become complex if the LLM's output format is highly variable.
*   **Impact on Performance:** Parsing and validation steps will introduce additional overhead to the proposal generation process.
Testing that will be done:
*   **Unit Tests for `Proposal` Class (or TypedDict) and Parsing:** Unit tests will be created to ensure the parsing logic correctly extracts the required information from various LLM output formats, including edge cases and error conditions. These tests will validate the data types and structure of the parsed output.
*   **Integration Tests for `FounderAI`:** Integration tests will be conducted to verify that the `FounderAI` generates proposals in the correct structured format, and that the parsing and validation process functions as expected. These tests will involve mocking the LLM interaction.
*   **End-to-End Tests (Manual and Potentially Automated):** Manual testing will be performed to evaluate the quality and usefulness of the generated proposals. The end-to-end test will also ensure that the overall process of generating and validating proposals is stable and functions as expected.

## Files to Change:
- src/prompts/founder.txt
- src/agents/founder.py
- src/models/proposal.py (new file)
- src/agents/code_reader.py
- tests/test_founder_ai.py (new file)
- tests/test_proposal.py (new file)

## Original Proposal from Founder:
Okay, I've reviewed the project information. I will focus on improving the **Founder AI's** ability to generate high-quality and relevant improvement proposals. I will target the `src/agents/founder.py` file and the `src/prompts/founder.txt` file, as they are central to the Founder AI's functionality.

**1. Analysis of current state**

*   **Strengths:** The existing system has a `FounderAI` that receives a code summary and uses it to propose improvements. The system includes caching to reduce redundant calls. It also uses a system prompt.
*   **Weaknesses:**
    *   The `generate_proposal` method in `src/agents/founder.py` is basic. It takes a summary and calls a `generate_response` method, which likely interacts directly with the LLM. The proposal generation process lacks detailed information about areas for improvements.
    *   The `src/prompts/founder.txt` file is a basic description, but may not be well designed to elicit useful information from the system.
    *   There is no validation of the proposal.
    *   Lack of mechanism to encourage iterative proposal improvements.

**2. Proposed Improvement**

I propose enhancing the `FounderAI` to generate more structured and actionable improvement proposals by:

1.  **Improving the Prompt:** Modify the `src/prompts/founder.txt` to explicitly request structured output and guide the Founder AI in a multi-step reasoning process. The new prompt will instruct the AI to first identify the area for improvement, then explain *why* this area is important (benefit/impact), and then finally *how* the change can be achieved, and *what potential risks* are associated with the improvement. The prompt should also suggest the level of effort.
2.  **Implement Structured Output Parsing:** Implement a method for parsing the structured output from the AI, converting the response into a Python dictionary, and validating the result. This will involve defining a `Proposal` class to contain the parsed data, and using a parser to validate the output format.
3.  **Add Context to the Code Reader:** Pass information about the type of file as part of the `code_summary`, so the `FounderAI` can better understand how to improve this code.
4.  **Iterative Proposal Refinement (Future Implementation):** The `FounderAI` could be enhanced by requesting review from Developer AI. This feature is out of scope of the current improvements.

**3. Priority level (1-5)**

3

**4. Success criteria**

*   The `FounderAI` generates structured improvement proposals in a defined format, containing a clear area for improvement, rationale, suggested changes, risk assessment, and effort level.
*   The improved proposals are more specific and actionable, leading to more effective code changes.
*   The parsing and validation of the structured output are successful.
*   The system functions as expected without errors.

**5. Potential risks**

*   The LLM might not consistently generate output in the requested structured format, requiring prompt refinement or more robust parsing logic.
*   The parsing logic could be overly complex and difficult to maintain.
*   The structured format might restrict the creativity of the Founder AI.
*   Changes to the `src/prompts/founder.txt` file could negatively affect the quality of the generated proposals, if the prompt is not clear or well written.

